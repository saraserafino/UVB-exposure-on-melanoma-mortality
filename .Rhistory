# Packages
require(dplyr)
require(ggplot2)
# install.packages("vcfR")
require(vcfR)
install.packages("vcfR")
require(vcfR)
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
# VCF - Variant Calling Format - of a multi-region tumour (WGS ~80x median coverage)
VCF_url = "https://raw.githubusercontent.com/caravagnalab/CNAqc_datasets/main/MSeq_Set06/Mutations/Set.06.WGS.merged_filtered.vcf"
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
file.remove("Set.06.WGS.merged_filtered.vcf")
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
# Packages
require(dplyr)
require(ggplot2)
# install.packages("vcfR")
require(vcfR)
# VCF - Variant Calling Format - of a multi-region tumour (WGS ~80x median coverage)
VCF_url = "https://raw.githubusercontent.com/caravagnalab/CNAqc_datasets/main/MSeq_Set06/Mutations/Set.06.WGS.merged_filtered.vcf"
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
# VCF
print(set6)
# INFO fields
info_tidy = vcfR::extract_info_tidy(set6)
set6@meta %>% grep("FR,", ., value = T)
set6@meta %>% grep("TR,", ., value = T)
set6@meta %>% grep("NR,", ., value = T)
set6@meta %>% grep("NF,", ., value = T)
# Fixed fields (mutation coordinates, chr|from|ref|alt)
fix_tidy = set6@fix %>%
as_tibble %>%
rename(
chr = CHROM,#chromosome
from = POS,#position
ref = REF,
alt = ALT
) %>%
mutate(from = as.numeric(from), to = from + nchar(alt))
# Genotypes
geno_tidy = vcfR::extract_gt_tidy(set6) %>%
group_split(Indiv)
# Genotypes (gt)
geno_tidy = vcfR::extract_gt_tidy(set6) %>%
group_split(Indiv)
#we put together this informations
# Sample mutations in the CNAqc format
sample_mutations = lapply(
geno_tidy,
function(x)
{
bind_cols(info_tidy, fix_tidy) %>%
full_join(x, by = "Key") %>%
mutate(DP = as.numeric(gt_NR), NV = as.numeric(gt_NV)) %>%
mutate(VAF = NV / DP) %>%
select(chr, from, to, ref, alt, NV, DP, VAF, everything()) %>%
filter(!is.na(VAF), VAF > 0) # VAF > 0 in each sample
})
# Packages
require(dplyr)
require(ggplot2)
# install.packages("vcfR")
require(vcfR)
# VCF - Variant Calling Format - of a multi-region tumour (WGS ~80x median coverage)
VCF_url = "https://raw.githubusercontent.com/caravagnalab/CNAqc_datasets/main/MSeq_Set06/Mutations/Set.06.WGS.merged_filtered.vcf"
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
set6@meta #in meta there are the rows describing
set6@fix #in fix there is the content of second part
# so content of all the rows describing the mutations
set6@git #genotype informations
# VCF
print(set6)
# INFO fields
info_tidy = vcfR::extract_info_tidy(set6)
set6@meta %>% grep("FR,", ., value = T) #it tells you what FR is
set6@meta %>% grep("TR,", ., value = T) #it tells you what TR is
set6@meta %>% grep("NR,", ., value = T)
set6@meta %>% grep("NF,", ., value = T)
# Fixed fields (mutation coordinates, chr|from|ref|alt)
fix_tidy = set6@fix %>%
as_tibble %>%
rename(
chr = CHROM,#chromosome
from = POS,#position
ref = REF,
alt = ALT
) %>%
mutate(from = as.numeric(from), to = from + nchar(alt))
# Genotypes (gt)
geno_tidy = vcfR::extract_gt_tidy(set6) %>%
group_split(Indiv)
#we put together this informations
# Sample mutations in the CNAqc format
sample_mutations = lapply(
geno_tidy,
function(x)
{
bind_cols(info_tidy, fix_tidy) %>%
full_join(x, by = "Key") %>%
mutate(DP = as.numeric(gt_NR), NV = as.numeric(gt_NV)) %>%
mutate(VAF = NV / DP) %>%
select(chr, from, to, ref, alt, NV, DP, VAF, everything()) %>%
filter(!is.na(VAF), VAF > 0) # VAF > 0 in each sample
})
# A list for all samples available
names(sample_mutations) = sapply(sample_mutations, function(x) x$Indiv[1])
sample_mutations = sample_mutations[!is.na(names(sample_mutations))]
install.packages("vcfR")
install.packages("vcfR")
install.packages("vcfR")
install.packages("vcfR")
iris;
# learn the dataset iris through a package for tree learning
rpart(iris);
find.package('rpart');
# learn the dataset iris through a package for tree learning
rpart(iris);
find.package('rpart');
# learn the dataset iris through a package for tree learning
rpart();
#find.package('rpart'); # already have it
library(rpart); # load it
# learn the dataset iris through a package for tree learning
rpart(iris);
predict();
predict(rpart(iris));
devtools::install_github("caravagnalab/biPOD")
# we recommend running this is a fresh R session or restarting your current session
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
check_cmdstan_toolchain()
install_cmdstan()
cmdstan_version()
library(cmdstanr)
library(posterior)
library(bayesplot)
color_scheme_set("brightblue")
library(rstan)
remove.packages(c("StanHeaders", "rstan"))
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library(rstan)
library("rstan") # observe startup messages
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library("rstan") # observe startup messages
y <- as.matrix(read.table('https://raw.github.com/wiki/stan-dev/rstan/rats.txt', header = TRUE))
x <- c(8, 15, 22, 29, 36)
xbar <- mean(x)
N <- nrow(y)
T <- ncol(y)
rats_fit <- stan(file='https://raw.githubusercontent.com/stan-dev/example-models/master/bugs_examples/vol1/rats/rats.stan', data = list(N=N, T=T, y=y, x=x, xbar=xbar))
View(rats_fit)
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX17FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
file = M, sep = "\n", append = FALSE)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
library(rstan)
library(ggplot2)
library(rstanarm)
library(bayesplot)
library(tidyr) #per pivot_longer
library(dplyr) #per %>%
library(truncnorm) # per rnorm con valori minimi e massimi
library(loo)
library(lubridate) # progettato per semplificare il lavoro con le date
# Create custom palette because I wanted to distinguish well between countries
custom_palette <- c("#9F002E", "#BC72F0", "#FF50FF", "#FF7F00", "#FFB900", "#66E5FF", "#5FCEBE", "#00FF00", "#4DAF4A")
# Load the dataset
#install.packages("mlmRev")
library(mlmRev)
data("Mmmec")
# Check for missing values
colSums(is.na(Mmmec))
# Summary statistics of the deaths overall
summary(Mmmec$deaths)
# 25% of the observations has less than 8 deaths
# median(deaths) = 14.50
# mean(deaths) = 27.83
# 75% of the observations has less than 31 deaths
# max(deaths) = 313
# mean(deaths) = mean(expected deaths) = 27.8
summary(Mmmec$uvb)
# Generalized linear mixed model with frequentist approach (in particular ML approach)
M1 <- glmer(deaths ~ uvb + (1 | region) + (1 | nation), Mmmec, poisson, offset = log(expected))
# (1|region) includes varying intercepts for each region
# log(expected) is an offset term to adjust the model to account for the expected number of deaths
summary(M1)
# Bayes approach relying on HMC sampling from the posterior distribution
M1.rstanarm <- stan_glmer(deaths ~ uvb + (1 | region) + (1 | nation), Mmmec, poisson, offset = log(expected))
print(M1.rstanarm)
summary(M1.rstanarm)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
log_lik_M1rs <- log_lik(M1.rstanarm)
log_likelihood_M1rs <- sum(log_lik_M1rs)
print(log_likelihood_M1rs)
p <- length(M1.rstanarm$coefficients) # number of estimated parameters
n <- length(M1.rstanarm$y) # number of observations = 354
aic_M1rs <- - 2 * log_likelihood_M1rs + 2 * p
print(aic_M1rs)
bic_M1rs <- - 2 * log_likelihood_M1rs + log(n) * p
print(bic_M1rs)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
log_lik_M1rs <- log_lik(M1.rstanarm)
aic_M1rs <- - 2 * log_lik_M1rs + 2 * p
print(aic_M1rs)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
# Compute LOO
M1.rstanarm <- extract_log_lik(M1.rstanarm)
loo_1 <- loo(M1.rstanarm)
print(loo_1)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
# Compute LOO
M1.rstanarm <- extract_log_lik(M1.rstanarm)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
# Compute LOO
loo_M1rs <- loo(M1.rstanarm)
print(loo_M1rs)
# Generalized linear mixed model with frequentist approach (in particular ML approach)
M1 <- glmer(deaths ~ uvb + (1 | region), Mmmec, poisson, offset = log(expected))
# (1|region) includes varying intercepts for each region
# log(expected) is an offset term to adjust the model to account for the expected number of deaths
summary(M1)
# Bayes approach relying on HMC sampling from the posterior distribution
M1.rstanarm <- stan_glmer(deaths ~ uvb + (1 | region), Mmmec, poisson, offset = log(expected))
summary(M1.rstanarm)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
# Compute LOO
loo_M1rs <- loo(M1.rstanarm)
print(loo_M1rs)
# Bayes approach relying on HMC sampling from the posterior distribution
M1.rstanarm <- stan_glmer(deaths ~ uvb + (1 | region) + (1 | nation), Mmmec, poisson, offset = log(expected))
summary(M1.rstanarm)
# Compute AIC, BIC and log-likelihood for comparing with M1 results
# Compute LOO
loo_M1rs <- loo(M1.rstanarm)
print(loo_M1rs)
elpd_loo_value <- loo_M1rs$estimates["elpd_loo", "Estimate"]
print(elpd_loo_value)
p <- length(M1.rstanarm$coefficients) # number of estimated parameters
n <- length(M1.rstanarm$y) # number of observations = 354
aic_M1rs <- - 2 * elpd_loo_M1rs + 2 * p
elpd_loo_M1rs <- loo_M1rs$estimates["elpd_loo", "Estimate"]
print(elpd_loo_value)
aic_M1rs <- - 2 * elpd_loo_M1rs + 2 * p
print(aic_M1rs)
bic_M1rs <- - 2 * elpd_loo_M1rs + log(n) * p
print(bic_M1rs)
setwd("~/Desktop/Bayesian Statistics/progetto/UVB-exposure-on-melanoma-mortality")
# Posterior predictive check of reproduced data
pdf("images/densitiesM1rstanarm.pdf", width=8, height=7)
pp_check(M1.rstanarm)
dev.off()
# Plot the credible intervals
beta_names <- c(paste0("beta^", c("uvb")), "gl.intercept")
alpha_names<-c()
for (i in 1:51){
alpha_names[i] <- paste0(expression(alpha), "[", i,"]")
}
posterior_M1 <- as.matrix(M1.rstanarm)
pdf("images/logistic_credible_intervals.pdf", width=10, height=11)
mcmc_intervals(posterior_M1, regex_pars=c( "uvb",
"(Intercept)", "b"))+
xaxis_text(on =TRUE, size=rel(1.9))+
yaxis_text(on =TRUE, size=rel(1.4))+
scale_y_discrete(labels = ((parse(text= c(beta_names, alpha_names)))))
dev.off()
# Plot the posterior marginal densities along with 50% intervals for the ‘fixed-effects’ uvb
mcmc_areas(posterior_M1, regex_pars = c("uvb"))+
xaxis_text(on =TRUE, size=rel(1.9))+
yaxis_text(on =TRUE, size=rel(1.4))
ggsave(file = "images/logistic_fixed_effects.pdf", width=8, height=7)
# Plot the random effects (posterior mean +- s.e.)
pdf("images/random_effects_log.pdf", height =7, width =11)
int_ord <- sort(coef(M1.rstanarm)$region[,1], index.return=TRUE)$x
ord <- sort(coef(M1.rstanarm)$region[,1], index.return=TRUE)$ix
region.abbr <- as.character(1:79)
region.abbr.ord <- region.abbr[ord]
se_ord <- M1.rstanarm$ses[ord]
par(xaxt="n", mfrow=c(1,1), mar = c(5,2,2,1))
plot(1:length(int_ord), int_ord, ylim=c(-1.4,1.4), pch=19, bg=2, xlab="Regions",
ylab="Intercepts",  cex.main=1.9, cex.lab=1.9)
for (h in 1:length(int_ord)){
segments(h, int_ord[h]-se_ord[h], h, int_ord[h]+se_ord[h], col="red")
is.wholenumber <-
function(x, tol = .Machine$double.eps^0.5)
abs(x - round(x)) < tol
if (is.wholenumber(h/2)){
text(h, int_ord[h]+se_ord[h]+0.1, region.abbr.ord[h], cex=1.1)}else{
text(h, int_ord[h]-se_ord[h]-0.1, region.abbr.ord[h], cex=1.1)
}
}
dev.off()
# Create UVB index as in Table III of the paper
uvbi_params <- data.frame(
nation = c(unique(Mmmec$nation)),
mean_UVBI = c(12.70, 12.79, 9.96, 17.18, 10.91, 21.45, 10.54, 13.26, 11.40),
sd_UVBI = c(0.29, 1.35, 0.38, 2.59, 1.50, 3.51, 0.60, 0.05, 0.47),
min_UVBI = c(12.17, 10.45, 9.47, 12.92, 6.69, 16.83, 9.64, 13.22, 10.62),
max_UVBI = c(13.10, 15.15, 10.49, 23.24, 13.46, 28.95, 11.70, 13.31, 11.94)
)
# Join UVBI data to the dataframe Mmmec
Mmmec2 <- left_join(Mmmec, uvbi_params, by = "nation")
# From mean_UVBI and sd_UVBI generate UVBI values for each county, respecting min_UVBI and max_UVBI
Mmmec2 <- Mmmec2 %>%
mutate(UVBI = rtruncnorm(n(), a = min_UVBI, b = max_UVBI, mean = mean_UVBI, sd = sd_UVBI))
stan_data <- list(
N = nrow(Mmmec2),
deaths = Mmmec2$deaths,
expected = Mmmec2$expected,
K = length(unique(Mmmec2$nation)),
J = length(unique(Mmmec2$region)),
k = as.integer(as.factor(Mmmec2$nation)),
j = as.integer(as.factor(Mmmec2$region)),
UVBI = Mmmec2$UVBI
)
comp_model_A <- stan_model('poisson_regression.stan')
fit_model_A <- sampling(comp_model_A, data = stan_data, seed = 123)
print(fit_model_A, pars = c('beta0','beta1','sigma_s','sigma_u','sigma_e'))
y_rep <- as.matrix(fit_model_A, pars = "y_rep")
# Compute AIC, BIC and log-likelihood for comparing with previous results
log_lik_A <- extract_log_lik(fit_model_A)
loo_A <- loo(log_lik_A)
print(loo_A)
elpd_loo_M1rs <- loo_M1rs$estimates["elpd_loo", "Estimate"]
elpd_loo_A <- loo_A$estimates["elpd_loo", "Estimate"]
p <- 5 + length(unique(Mmmec2$nation)) + length(unique(Mmmec2$region)) + nrow(Mmmec2) # number of estimated parameters
aic_A <- - 2 * elpd_loo_A + 2 * p
print(aic_A)
bic_A <- - 2 * elpd_loo_A + log(n) * p
print(bic_A)
