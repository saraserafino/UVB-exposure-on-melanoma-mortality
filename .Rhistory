# Packages
require(dplyr)
require(ggplot2)
# install.packages("vcfR")
require(vcfR)
install.packages("vcfR")
require(vcfR)
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
# VCF - Variant Calling Format - of a multi-region tumour (WGS ~80x median coverage)
VCF_url = "https://raw.githubusercontent.com/caravagnalab/CNAqc_datasets/main/MSeq_Set06/Mutations/Set.06.WGS.merged_filtered.vcf"
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
file.remove("Set.06.WGS.merged_filtered.vcf")
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
# Packages
require(dplyr)
require(ggplot2)
# install.packages("vcfR")
require(vcfR)
# VCF - Variant Calling Format - of a multi-region tumour (WGS ~80x median coverage)
VCF_url = "https://raw.githubusercontent.com/caravagnalab/CNAqc_datasets/main/MSeq_Set06/Mutations/Set.06.WGS.merged_filtered.vcf"
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
# VCF
print(set6)
# INFO fields
info_tidy = vcfR::extract_info_tidy(set6)
set6@meta %>% grep("FR,", ., value = T)
set6@meta %>% grep("TR,", ., value = T)
set6@meta %>% grep("NR,", ., value = T)
set6@meta %>% grep("NF,", ., value = T)
# Fixed fields (mutation coordinates, chr|from|ref|alt)
fix_tidy = set6@fix %>%
as_tibble %>%
rename(
chr = CHROM,#chromosome
from = POS,#position
ref = REF,
alt = ALT
) %>%
mutate(from = as.numeric(from), to = from + nchar(alt))
# Genotypes
geno_tidy = vcfR::extract_gt_tidy(set6) %>%
group_split(Indiv)
# Genotypes (gt)
geno_tidy = vcfR::extract_gt_tidy(set6) %>%
group_split(Indiv)
#we put together this informations
# Sample mutations in the CNAqc format
sample_mutations = lapply(
geno_tidy,
function(x)
{
bind_cols(info_tidy, fix_tidy) %>%
full_join(x, by = "Key") %>%
mutate(DP = as.numeric(gt_NR), NV = as.numeric(gt_NV)) %>%
mutate(VAF = NV / DP) %>%
select(chr, from, to, ref, alt, NV, DP, VAF, everything()) %>%
filter(!is.na(VAF), VAF > 0) # VAF > 0 in each sample
})
# Packages
require(dplyr)
require(ggplot2)
# install.packages("vcfR")
require(vcfR)
# VCF - Variant Calling Format - of a multi-region tumour (WGS ~80x median coverage)
VCF_url = "https://raw.githubusercontent.com/caravagnalab/CNAqc_datasets/main/MSeq_Set06/Mutations/Set.06.WGS.merged_filtered.vcf"
# Download, load and cancel data
download.file(VCF_url, "Set.06.WGS.merged_filtered.vcf",)
set6 = vcfR::read.vcfR("Set.06.WGS.merged_filtered.vcf")
set6@meta #in meta there are the rows describing
set6@fix #in fix there is the content of second part
# so content of all the rows describing the mutations
set6@git #genotype informations
# VCF
print(set6)
# INFO fields
info_tidy = vcfR::extract_info_tidy(set6)
set6@meta %>% grep("FR,", ., value = T) #it tells you what FR is
set6@meta %>% grep("TR,", ., value = T) #it tells you what TR is
set6@meta %>% grep("NR,", ., value = T)
set6@meta %>% grep("NF,", ., value = T)
# Fixed fields (mutation coordinates, chr|from|ref|alt)
fix_tidy = set6@fix %>%
as_tibble %>%
rename(
chr = CHROM,#chromosome
from = POS,#position
ref = REF,
alt = ALT
) %>%
mutate(from = as.numeric(from), to = from + nchar(alt))
# Genotypes (gt)
geno_tidy = vcfR::extract_gt_tidy(set6) %>%
group_split(Indiv)
#we put together this informations
# Sample mutations in the CNAqc format
sample_mutations = lapply(
geno_tidy,
function(x)
{
bind_cols(info_tidy, fix_tidy) %>%
full_join(x, by = "Key") %>%
mutate(DP = as.numeric(gt_NR), NV = as.numeric(gt_NV)) %>%
mutate(VAF = NV / DP) %>%
select(chr, from, to, ref, alt, NV, DP, VAF, everything()) %>%
filter(!is.na(VAF), VAF > 0) # VAF > 0 in each sample
})
# A list for all samples available
names(sample_mutations) = sapply(sample_mutations, function(x) x$Indiv[1])
sample_mutations = sample_mutations[!is.na(names(sample_mutations))]
install.packages("vcfR")
install.packages("vcfR")
install.packages("vcfR")
install.packages("vcfR")
iris;
# learn the dataset iris through a package for tree learning
rpart(iris);
find.package('rpart');
# learn the dataset iris through a package for tree learning
rpart(iris);
find.package('rpart');
# learn the dataset iris through a package for tree learning
rpart();
#find.package('rpart'); # already have it
library(rpart); # load it
# learn the dataset iris through a package for tree learning
rpart(iris);
predict();
predict(rpart(iris));
devtools::install_github("caravagnalab/biPOD")
# we recommend running this is a fresh R session or restarting your current session
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
check_cmdstan_toolchain()
install_cmdstan()
cmdstan_version()
library(cmdstanr)
library(posterior)
library(bayesplot)
color_scheme_set("brightblue")
library(rstan)
remove.packages(c("StanHeaders", "rstan"))
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library(rstan)
library("rstan") # observe startup messages
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library("rstan") # observe startup messages
y <- as.matrix(read.table('https://raw.github.com/wiki/stan-dev/rstan/rats.txt', header = TRUE))
x <- c(8, 15, 22, 29, 36)
xbar <- mean(x)
N <- nrow(y)
T <- ncol(y)
rats_fit <- stan(file='https://raw.githubusercontent.com/stan-dev/example-models/master/bugs_examples/vol1/rats/rats.stan', data = list(N=N, T=T, y=y, x=x, xbar=xbar))
View(rats_fit)
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX17FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
file = M, sep = "\n", append = FALSE)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
library(rstan)
library(ggplot2)
library(rstanarm)
library(bayesplot)
library(tidyr) #per pivot_longer
library(dplyr) #per %>%
library(truncnorm) # per rnorm con valori minimi e massimi
library(loo)
library(lubridate) # progettato per semplificare il lavoro con le date
# Create custom palette because I wanted to distinguish well between countries
custom_palette <- c("#9F002E", "#BC72F0", "#FF50FF", "#FF7F00", "#FFB900", "#66E5FF", "#5FCEBE", "#00FF00", "#4DAF4A")
# Load the dataset
#install.packages("mlmRev")
library(mlmRev)
data("Mmmec")
# Bayes approach relying on HMC sampling from the posterior distribution
M1.rstanarm <- stan_glmer(deaths ~ uvb + (1 | region) + (1 | nation), Mmmec, poisson, offset = log(expected))
print(M1.rstanarm)
summary(M1.rstanarm)
# Compute AIC and BIC for comparing with M1 results
loo_M1rs <- loo(M1.rstanarm) # extract LOO
print(loo_M1rs)
elpd_loo_M1rs <- loo_M1rs$estimates["elpd_loo", "Estimate"]
p <- length(M1.rstanarm$coefficients) # number of estimated parameters
n <- length(M1.rstanarm$y) # number of observations = 354
aic_M1rs <- - 2 * elpd_loo_M1rs + 2 * p
print(aic_M1rs) # AIC
bic_M1rs <- - 2 * elpd_loo_M1rs + log(n) * p
print(bic_M1rs) # BIC
# Create UVB index as in Table III of the paper
uvbi_params <- data.frame(
nation = c(unique(Mmmec$nation)),
mean_UVBI = c(12.70, 12.79, 9.96, 17.18, 10.91, 21.45, 10.54, 13.26, 11.40),
sd_UVBI = c(0.29, 1.35, 0.38, 2.59, 1.50, 3.51, 0.60, 0.05, 0.47),
min_UVBI = c(12.17, 10.45, 9.47, 12.92, 6.69, 16.83, 9.64, 13.22, 10.62),
max_UVBI = c(13.10, 15.15, 10.49, 23.24, 13.46, 28.95, 11.70, 13.31, 11.94)
)
# Join UVBI data to the dataframe Mmmec
Mmmec2 <- left_join(Mmmec, uvbi_params, by = "nation")
# From mean_UVBI and sd_UVBI generate UVBI values for each county, respecting min_UVBI and max_UVBI
Mmmec2 <- Mmmec2 %>%
mutate(UVBI = rtruncnorm(n(), a = min_UVBI, b = max_UVBI, mean = mean_UVBI, sd = sd_UVBI))
stan_data <- list(
N = nrow(Mmmec2),
deaths = Mmmec2$deaths,
expected = Mmmec2$expected,
K = length(unique(Mmmec2$nation)),
J = length(unique(Mmmec2$region)),
k = as.integer(as.factor(Mmmec2$nation)),
j = as.integer(as.factor(Mmmec2$region)),
UVBI = Mmmec2$UVBI
)
comp_model_A <- stan_model('poisson_regression.stan')
setwd("~/Desktop/Bayesian Statistics/progetto/UVB-exposure-on-melanoma-mortality")
comp_model_A <- stan_model('poisson_regression.stan')
fit_model_A <- sampling(comp_model_A, data = stan_data, seed = 123)
print(fit_model_A, pars = c('beta0','beta1','sigma_s','sigma_u','sigma_e'))
y_rep <- as.matrix(fit_model_A, pars = "y_rep")
# Compute AIC, BIC and log-likelihood for comparing with previous results
log_lik_A <- extract_log_lik(fit_model_A)
loo_A <- loo(log_lik_A)
print(loo_A)
elpd_loo_A <- loo_A$estimates["elpd_loo", "Estimate"]
p <- 5 + length(unique(Mmmec2$nation)) + length(unique(Mmmec2$region)) + nrow(Mmmec2) # number of estimated parameters
aic_A <- - 2 * elpd_loo_A
print(aic_A)
bic_A <- - 2 * elpd_loo_A
print(bic_A)
# Calcola AIC
AIC <- 2 * p - 2 * elpd_loo_A
print(AIC)
BIC <- log(n) * p - 2 * elpd_loo_A
print(BIC)
# Calcola AIC
aic_A <- - 2 * elpd_loo_A + 2 * p
print(aic_A) # AIC
bic_A <- - 2 * elpd_loo_A + log(n) * p
print(bic_A) # BIC
# Definizione dei parametri
sigma <- 3.6
mu_base <- 45.9
mu_slope <- 3.2
x_values <- 1:15
# Calcolo della log-likelihood per ciascun x_i e somma totale
log_likelihood_sum <- sum(sapply(x_values, function(x_i) {
mu_i <- mu_base + mu_slope * x_i
-0.5 * log(2 * pi * sigma^2) - ((x_i - mu_i)^2) / (2 * sigma^2)
}))
# Stampa del risultato
print(log_likelihood_sum)
# Calcolo della log-likelihood per ciascun x_i e somma totale
log_likelihood_sum <- sum(sapply(x_values, function(x_i) {
mu_i <- mu_base + mu_slope * x_i
-0.5 * log(2 * pi * sigma^2) - ((x_i - mu_i)^2) / (2 * sigma^2)
}))
# Stampa del risultato
print(log_likelihood_sum)
# Definizione dei parametri
sigma <- 3.6
mu_base <- 45.9
mu_slope <- 3.2
x_values <- 1:15
# Calcolo della log-likelihood per ciascun x_i e somma totale
log_likelihood_sum <- sum(sapply(x_values, function(x_i) {
mu_i <- mu_base + mu_slope * x_i
-0.5 * log(2 * pi * sigma^2) - ((x_i - mu_i)^2) / (2 * sigma^2)
}))
# Stampa del risultato
print(log_likelihood_sum)
print(aic_A)
print(bic_A)
print(aic_A) # AIC
aic_A <- - 2 * elpd_loo_A
print(aic_A)
bic_A <- - 2 * elpd_loo_A
print(bic_A)
# Calcola AIC
aic_A2 <- - 2 * elpd_loo_A + 2 * p
print(aic_A2) # AIC
bic_A2 <- - 2 * elpd_loo_A + log(n) * p
print(bic_A2) # BIC
print(loo_A)
print(-2*elpd_loo_M1rs)
print(aic_M1rs) # AIC
print(bic_M1rs) # BIC
print(log_lik_A)
print(sum(log_lik_A))
